{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   ipywidgets import interactive, fixed\n",
    "import matplotlib.pyplot as plt\n",
    "from   model.cnn import CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from   source.dataloader import ValidationDataGenerator\n",
    "from   source.gradcampp import model_modifier\n",
    "from   source.metrics import roc_auc\n",
    "from   source.preprocessing import get_preprocessed_polyp_segmentation_mask_info\n",
    "from   source.visualization import plotter_batch, plotter_gradcam\n",
    "import tensorflow as tf\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-fossil",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"preprocessed-data\"\n",
    "\n",
    "# Number of trained estimators in the ensemble\n",
    "n_estimators = 2\n",
    "\n",
    "# Image properties\n",
    "raw_image_size = (100,100,100)\n",
    "patch_size     = (50,50,50) # Field-of-view of the network\n",
    "n_channels     = 1 # 1 = CT image only, 2 = CT image + manual expert segmentation mask\n",
    "\n",
    "# Fix global seed (as good as possible) to ensure reproducibility of results\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-namibia",
   "metadata": {},
   "source": [
    "### Meta information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902182fd-ef92-432c-9add-11075f045f45",
   "metadata": {},
   "source": [
    "Load information of the CT scans from 'ct_info.csv' and get a list of the preprocessed ct scans and segmentation masks that are available in 'preprocessed-data/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ct_info = pd.read_csv('ct_info.csv')\n",
    "df_ct_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_info = get_preprocessed_polyp_segmentation_mask_info(data_dir)\n",
    "df_preprocessed_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946d88a-218a-4b42-b027-08a73b79d88d",
   "metadata": {},
   "source": [
    "Merge information into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bb52d-d605-4a4e-bc5f-e1203c92480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_ct_info.merge(df_preprocessed_info, how='inner', on=['patient', 'polyp', 'segmentation'])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-sellers",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ValidationDataGenerator(data=df_data,\n",
    "                                         batch_size=df_data.shape[0],\n",
    "                                         patch_size=patch_size,\n",
    "                                         n_channels=n_channels,\n",
    "                                         num_threads=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-measurement",
   "metadata": {},
   "source": [
    "### Inspect test batches (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch   = data_generator[0]\n",
    "X_test_batch = test_batch[0]\n",
    "y_test_batch = test_batch[1]\n",
    "print('X_test_batch:', X_test_batch.shape, ', y_test_batch:', y_test_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter_batch,\n",
    "            batch        = fixed(test_batch),\n",
    "            sample_nr    = (0,X_test_batch.shape[0]-1),\n",
    "            channel      = (0,X_test_batch.shape[4]-1),\n",
    "            slice_x      = (0,X_test_batch.shape[1]-1),\n",
    "            slice_y      = (0,X_test_batch.shape[2]-1),\n",
    "            slice_z      = (0,X_test_batch.shape[3]-1),\n",
    "            cmap         = [\"gist_yarg\", \"cool\", \"inferno\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-subsection",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_shape=(50, 50, 50, n_channels), classes=1, dropout=0.1, mc=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-lesbian",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for est in range(n_estimators):\n",
    "    \n",
    "    print('\\nEstimator: {:d}'.format(est))\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    weights = 'weights/ResNet18_3D_Dropout_SingleChannel_Ensemble_{:s}'.format(str(est+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\tLoad weights: {:s}'.format(weights))\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    # Predict\n",
    "    predictions_estimator = np.asarray(model.predict(data_generator))\n",
    "    predictions.append(predictions_estimator)\n",
    "    \n",
    "predictions = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9f4bf-5a38-4b23-9703-3caae40a39e4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = np.asarray(data_generator[0][1])\n",
    "\n",
    "# Ensemble predictions\n",
    "y_pred_ensemble = np.mean(predictions.squeeze(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC-AUC\n",
    "ensemble_roc_auc = roc_auc(y_true, y_pred_ensemble).numpy()\n",
    "print('ROC_AUC = {:.2f}'.format(ensemble_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-marketing",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fcc1d4-2a64-4250-8c1a-4ef1f4d559c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_loss(output):\n",
    "    loss_list  = [output[i][0] for i in range(df_data.shape[0])]\n",
    "    loss_tuple = tuple(loss_list)\n",
    "    return loss_tuple # (output[0][true_class[0]], output[1][true_class[1]], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.gradcam import GradcamPlusPlus\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "cams = []\n",
    "\n",
    "for est in range(n_estimators):\n",
    "    \n",
    "    print('\\nGradCAM++ for Estimator {:d}'.format(est))\n",
    "    \n",
    "    ##############################\n",
    "    ######### CNN Model ##########\n",
    "    ##############################\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    weights = 'weights/ResNet18_3D_Dropout_SingleChannel_Ensemble_{:s}'.format(str(est+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\tLoad weights: {:s}'.format(weights))\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    ############################\n",
    "    ######### GradCAM ##########\n",
    "    ############################\n",
    "    \n",
    "    # Create Gradcam object\n",
    "    gradcam = GradcamPlusPlus(model,\n",
    "                              model_modifier=model_modifier,\n",
    "                              clone=False)\n",
    "\n",
    "    # Generate heatmap with GradCAM form first neuron\n",
    "    cam_est = gradcam(gc_loss,\n",
    "                      X_test_batch,\n",
    "                      penultimate_layer=47, # model.layers number\n",
    "                      seek_penultimate_conv_layer=False)\n",
    "    cam_est = normalize(cam_est)\n",
    "    \n",
    "    # Store GradCAM\n",
    "    cams.append(cam_est)\n",
    "    \n",
    "cams = np.asarray(cams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[47].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-theorem",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_generator = ValidationDataGenerator(data=df_data,\n",
    "                                             batch_size=df_data.shape[0],\n",
    "                                             patch_size=patch_size,\n",
    "                                             n_channels=2,\n",
    "                                             num_threads=1,\n",
    "                                             shuffle=False)\n",
    "\n",
    "\n",
    "X_seg = seg_data_generator[0][0][...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter_gradcam,\n",
    "            X            = fixed(X_test_batch),\n",
    "            cam          = fixed(cams),\n",
    "            seg          = fixed(X_seg),\n",
    "            y_true       = fixed(y_true),\n",
    "            y_pred       = fixed(y_pred_ensemble),\n",
    "            sample_nr    = (0,X_test_batch.shape[0]-1),\n",
    "            cam_nr       = (0,cams.shape[0]-1),\n",
    "            modality     = (0,X_test_batch.shape[4]-1),\n",
    "            slice_x      = (0,X_test_batch.shape[1]-1),\n",
    "            slice_y      = (0,X_test_batch.shape[2]-1),\n",
    "            slice_z      = (0,X_test_batch.shape[3]-1),\n",
    "            alpha        = (0.0,1.0),\n",
    "            threshold    = (0.0,1.0,0.05),\n",
    "            cmap         = [\"inferno\", \"cool\", \"gist_yarg\", \"jet\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-ordinary",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GradCAM++ activation in segmented voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd5c59-ecde-4e8c-b545-6e93495c6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voxels_seg = X_seg[X_seg==1.0].shape[0]\n",
    "\n",
    "aggregated_cam             = np.mean(cams, axis=0)\n",
    "aggregated_cam[X_seg==0.0] = 0.0\n",
    "n_voxels_high_act          = aggregated_cam[aggregated_cam>=activation_threshold].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8da483-bae0-407a-9420-83cd8ce5791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_high_act = float(n_voxels_high_act) / float(n_voxels_seg)\n",
    "print('Fraction of segmented voxels with a GradCAM++ activation > {:.2f}: {:.2f}% ({:d}/{:d})'.format(activation_threshold, 100*p_high_act, n_voxels_high_act, n_voxels_seg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
