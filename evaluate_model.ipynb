{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "professional-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from   ipywidgets import interactive, fixed\n",
    "import matplotlib.pyplot as plt\n",
    "from   model.cnn import CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from   source.dataloader import ValidationDataGenerator\n",
    "from   source.metrics import roc_auc\n",
    "from   source.preprocessing import get_preprocessed_polyp_segmentation_mask_info\n",
    "from   source.visualization import plotter_batch\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-psychology",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conservative-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"preprocessed-data\"\n",
    "\n",
    "# Repeated runs\n",
    "n_estimators = 2\n",
    "\n",
    "# Data\n",
    "raw_image_size = (100,100,100)\n",
    "\n",
    "# Neural network\n",
    "patch_size = (50,50,50)\n",
    "\n",
    "# Data, second channel and gaussian blob\n",
    "n_channels = 2\n",
    "\n",
    "# Fix global seed (as good as possible)\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-leeds",
   "metadata": {},
   "source": [
    "### Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exotic-alfred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>polyp</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ct</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>seg</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ct</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>seg</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ct</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>seg</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient polyp segmentation type  \\\n",
       "0       1     1            1   ct   \n",
       "1       1     1            1  seg   \n",
       "2       2     2            2   ct   \n",
       "3       2     2            2  seg   \n",
       "4       3     3            3   ct   \n",
       "5       3     3            3  seg   \n",
       "\n",
       "                                                file  \n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "1  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "3  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "4  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "5  /home/philipp/Projects/deep-learning-ct-colono...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polyp_seg_masks = get_preprocessed_polyp_segmentation_mask_info(data_dir)\n",
    "df_polyp_seg_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv('ct_info.csv')\n",
    "df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-classics",
   "metadata": {},
   "source": [
    "#### Keras datagenerator (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ValidationDataGenerator(data=patients,\n",
    "                                         batch_size=len(patients),\n",
    "                                         patch_size=patch_size,\n",
    "                                         n_channels=n_channels,\n",
    "                                         num_threads=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-nickname",
   "metadata": {},
   "source": [
    "#### Inspect test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch   = data_generator[0]\n",
    "X_test_batch = test_batch[0]\n",
    "y_test_batch = test_batch[1]\n",
    "print('X_test_batch:', X_test_batch.shape, ', y_test_batch:', y_test_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter_batch,\n",
    "            batch        = fixed(test_batch),\n",
    "            sample_nr    = (0,X_test_batch.shape[0]-1),\n",
    "            channel      = (0,X_test_batch.shape[4]-1),\n",
    "            slice_x      = (0,X_test_batch.shape[1]-1),\n",
    "            slice_y      = (0,X_test_batch.shape[2]-1),\n",
    "            slice_z      = (0,X_test_batch.shape[3]-1),\n",
    "            cmap         = [\"gist_yarg\", \"cool\", \"inferno\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-pacific",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_shape=(50, 50, 50, n_channels), classes=1, dropout=0.1, mc=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-earthquake",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for run in range(n_estimators):\n",
    "    \n",
    "    print('\\nRun #{:d}'.format(run))\n",
    "    \n",
    "    ##############################\n",
    "    ######### CNN Model ##########\n",
    "    ##############################\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    weights = 'weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_{:s}'.format(str(run+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\nLoad weights: {:s}'.format(weights))\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    #########################################\n",
    "    ######### Validation & Testing ##########\n",
    "    #########################################\n",
    "    \n",
    "    # Model predictions\n",
    "    predictions_estimator = np.asarray(model.predict(data_generator))\n",
    "    \n",
    "    # Store predictions\n",
    "    predictions.append(predictions_estimator)\n",
    "    \n",
    "predictions = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-basket",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator_2 = RVCValidDataGenerator3D(data=patients,\n",
    "                                                batch_size=len(patients),\n",
    "                                                patch_size=patch_size,\n",
    "                                                num_modalities=num_modalities,\n",
    "                                                dataset=dataset,\n",
    "                                                second_channel=second_channel,\n",
    "                                                sigma=sigma,\n",
    "                                                hu_range=[-450,650],\n",
    "                                                num_threads=20,\n",
    "                                                one_hot=False,\n",
    "                                                shuffle=False)\n",
    "test_batch_2 = test_data_generator_2[0]\n",
    "X_test       = test_batch_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = np.asarray(data_generator[0][1])\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble predictions\n",
    "y_pred_ensemble = np.mean(predictions.squeeze(), axis=0)\n",
    "y_pred_ensemble.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-delicious",
   "metadata": {},
   "source": [
    "#### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_roc_auc = roc_auc(y_true, y_pred_ensemble).numpy()\n",
    "print('ROC_AUC = {:.2f}'.format(ensemble_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = np.concatenate([np.expand_dims(y_pred_ensemble, -1), np.expand_dims(y_true, -1)], 1)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_file = 'results/ensemble/external_validation_set/results_{:s}.npy'.format(model_name)\n",
    "#print('Save results: {:s}'.format(results_file))\n",
    "#np.save(results_file, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-honolulu",
   "metadata": {},
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output):\n",
    "    loss_list  = [output[i][0] for i in range(len(patients))]\n",
    "    loss_tuple = tuple(loss_list)\n",
    "    return loss_tuple # (output[0][true_class[0]], output[1][true_class[1]], ...)\n",
    "\n",
    "def model_modifier(m):\n",
    "    m.layers[-1].activation = tf.keras.activations.linear\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[47].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.gradcam import GradcamPlusPlus\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "cams = []\n",
    "\n",
    "for run in range(n_runs_total):\n",
    "    \n",
    "    print('\\nRun #{:d}'.format(run))\n",
    "    \n",
    "    ##############################\n",
    "    ######### CNN Model ##########\n",
    "    ##############################\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    pretrained_weights = 'weights/ensemble/{:s}_{:s}'.format(model_name, str(run+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\nLoad weights: {:s}'.format(pretrained_weights))\n",
    "    model.load_weights(pretrained_weights)\n",
    "    \n",
    "    ############################\n",
    "    ######### GradCAM ##########\n",
    "    ############################\n",
    "    \n",
    "    # Create Gradcam object\n",
    "    gradcam = GradcamPlusPlus(model,\n",
    "                              model_modifier=model_modifier,\n",
    "                              clone=False)\n",
    "\n",
    "    # Generate heatmap with GradCAM form first neuron\n",
    "    cam_run = gradcam(loss,\n",
    "                      X_test,\n",
    "                      penultimate_layer=47, # model.layers number\n",
    "                      seek_penultimate_conv_layer=False)\n",
    "    cam_run = normalize(cam_run)\n",
    "    \n",
    "    # Store GradCAM\n",
    "    cams.append(cam_run)\n",
    "    \n",
    "cams = np.asarray(cams)\n",
    "cams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ensemble      = np.sum(cams, axis=0)\n",
    "norm_cam_ensemble = np.max(cam_ensemble.reshape(cam_ensemble.shape[0],-1),axis=1)\n",
    "\n",
    "for i in range(norm_cam_ensemble.shape[0]):\n",
    "    factor          = np.max(cam_ensemble[i])\n",
    "    cam_ensemble[i] = np.divide(cam_ensemble[i], factor)\n",
    "\n",
    "cam_ensemble = np.expand_dims(cam_ensemble, 0)\n",
    "cam_ensemble.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-sally",
   "metadata": {},
   "source": [
    "#### Plot GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_generator = RVCValidDataGenerator3D(data=patients,\n",
    "                                             batch_size=len(patients),\n",
    "                                             patch_size=patch_size,\n",
    "                                             num_modalities=2,\n",
    "                                             dataset=dataset,\n",
    "                                             second_channel='segmentation',\n",
    "                                             sigma=sigma,\n",
    "                                             num_threads=20,\n",
    "                                             one_hot=False,\n",
    "                                             shuffle=False)\n",
    "\n",
    "\n",
    "X_seg = seg_data_generator[0][0][...,1]\n",
    "len(X_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "def plotter_gradcam(X, cam, seg, cam_nr, modality, y_true, y_pred, sample_nr, slice_x, slice_y, slice_z, alpha, threshold, cmap, reverse_cmap):\n",
    "     \n",
    "    # Pick and normalize image\n",
    "    X = np.copy(X[sample_nr])\n",
    "    X[...,0] = np.divide(X[...,0],np.amax(X[...,0]))\n",
    "    if modality>0:\n",
    "        X[...,1] = np.divide(X[...,1],np.amax(X[...,1]))\n",
    "    \n",
    "    # Pick cam\n",
    "    cam = np.copy(cam[cam_nr,sample_nr,...])\n",
    "    \n",
    "    # Pick segmentation\n",
    "    seg = np.copy(seg[sample_nr])\n",
    "    \n",
    "    # Colormap\n",
    "    color_map = plt.cm.get_cmap(cmap)\n",
    "    if reverse_cmap:\n",
    "        color_map = color_map.reversed()\n",
    "        \n",
    "    print('Image {:d}: [{:.2f}, {:.2f}]'.format(sample_nr,np.amin(X),np.amax(X)))\n",
    "    print('Cam   {:d}: [{:.2f}, {:.2f}]'.format(sample_nr,np.amin(cam),np.amax(cam)))\n",
    "    print('True label: {:d}'.format(y_true[sample_nr]))\n",
    "    print('Prediction: {:.2f}'.format(y_pred[sample_nr]))\n",
    "    \n",
    "    # Threshold\n",
    "    #X_mask = np.zeros_like(X[...,modality])\n",
    "    #X_mask[np.where(cam>=threshold)]=1\n",
    "    #X_in = np.copy(X)\n",
    "    #X_in[...,modality] = np.multiply(X_in[...,modality], X_mask)\n",
    "    X_in = np.zeros_like(X[...,modality])\n",
    "    X_in[np.where(cam>=threshold)]=1\n",
    "    \n",
    "    #X_mask = np.zeros_like(X[...,modality])\n",
    "    #X_mask[np.where(cam<threshold)]=1\n",
    "    #X_out = np.copy(X)\n",
    "    #X_out[...,modality] = np.multiply(X_out[...,modality], X_mask)\n",
    "    X_out = np.zeros_like(X[...,modality])\n",
    "    \n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(14,7.6), sharex=True, sharey=True)\n",
    "    \n",
    "    # Original input image with GradCAM on top\n",
    "    ax[0,0].imshow(X[slice_x,:,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[0,1].imshow(X[:,slice_y,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[0,2].imshow(X[:,:,slice_z,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "\n",
    "    ax[0,0].imshow(cam[slice_x,:,:], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[0,1].imshow(cam[:,slice_y,:], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[0,2].imshow(cam[:,:,slice_z], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    \n",
    "    ax[0,0].set_xlabel('y', fontsize=16)\n",
    "    ax[0,0].set_ylabel('z', fontsize=16)\n",
    "    ax[0,1].set_xlabel('x', fontsize=16)\n",
    "    ax[0,1].set_ylabel('z', fontsize=16)\n",
    "    ax[0,2].set_xlabel('x', fontsize=16)\n",
    "    ax[0,2].set_ylabel('y', fontsize=16)\n",
    "    \n",
    "    im = plt.imshow(np.zeros((50,50)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=1.0)\n",
    "    \n",
    "    # Binarized CT\n",
    "    ax[1,0].imshow(X[slice_x,:,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[1,1].imshow(X[:,slice_y,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[1,2].imshow(X[:,:,slice_z,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    \n",
    "    ax[1,0].imshow(X_in[slice_x,:,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,1].imshow(X_in[:,slice_y,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,2].imshow(X_in[:,:,slice_z], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    \n",
    "    ax[1,0].imshow(X_out[slice_x,:,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,1].imshow(X_out[:,slice_y,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,2].imshow(X_out[:,:,slice_z], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    \n",
    "    ax[1,0].set_xlabel('y', fontsize=16)\n",
    "    ax[1,0].set_ylabel('z', fontsize=16)\n",
    "    ax[1,1].set_xlabel('x', fontsize=16)\n",
    "    ax[1,1].set_ylabel('z', fontsize=16)\n",
    "    ax[1,2].set_xlabel('x', fontsize=16)\n",
    "    ax[1,2].set_ylabel('y', fontsize=16)\n",
    "    \n",
    "    # Settings\n",
    "    for axis in ax.flatten():\n",
    "        axis.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.8, 0.09, 0.025, 0.885])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar_ax.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter_gradcam,\n",
    "            X            = fixed(X_test),\n",
    "            cam          = fixed(cam_ensemble),\n",
    "            seg          = fixed(X_seg),\n",
    "            y_true       = fixed(y_true),\n",
    "            y_pred       = fixed(y_pred_ensemble),\n",
    "            sample_nr    = (0,X_test.shape[0]-1),\n",
    "            cam_nr       = (0,cam_ensemble.shape[0]-1),\n",
    "            modality     = (0,X_test.shape[4]-1),\n",
    "            slice_x      = (0,X_test.shape[1]-1),\n",
    "            slice_y      = (0,X_test.shape[2]-1),\n",
    "            slice_z      = (0,X_test.shape[3]-1),\n",
    "            alpha        = (0.0,1.0),\n",
    "            threshold    = (0.0,1.0,0.05),\n",
    "            cmap         = [\"inferno\", \"cool\", \"gist_yarg\", \"jet\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-latest",
   "metadata": {},
   "source": [
    "### CAM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_thr = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cam_ensemble = np.copy(cam_ensemble)\n",
    "binary_cam_ensemble[cam_ensemble>=cam_thr]=1.0\n",
    "binary_cam_ensemble[cam_ensemble<cam_thr]=0.0\n",
    "binary_cam_ensemble.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_size     = [np.where(X_seg[i]==1.0)[0].shape[0] for i in range(X_test.shape[0])]\n",
    "act_seg_size = [np.sum(binary_cam_ensemble[0,i][np.where(X_seg[i]==1.0)]).astype(np.int32) for i in range(X_test.shape[0])]\n",
    "cam_score    = np.asarray(act_seg_size).astype(np.float32) / np.asarray(seg_size).astype(np.float32)\n",
    "cam_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MyAwesomeScore = {:.2f} +/- {:.2f}'.format(np.median(cam_score), np.percentile(cam_score, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-omaha",
   "metadata": {},
   "source": [
    "#### CAM score plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram parameters\n",
    "bins     = 50\n",
    "binrange = [0.0,1.0]\n",
    "\n",
    "# Model gaussian distribution\n",
    "x_cs          = np.linspace(np.min(cam_score)*0.9,np.max(cam_score)*1.1,num=100)\n",
    "normal_pdf_cs = norm.pdf(x_cs, loc=np.mean(cam_score), scale=np.std(cam_score))\n",
    "normal_pdf_cs = normal_pdf_cs / np.amax(normal_pdf_cs)\n",
    "counts_cs, _  = np.histogram(cam_score, bins=bins, range=binrange)\n",
    "normal_pdf_cs = normal_pdf_cs * np.amax(counts_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram and gaussian distribution\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(cam_score, bins=bins, binrange=binrange, color='cornflowerblue', label=('CAM score = {:.2f}+/-{:.2f}'.format(np.mean(cam_score), np.std(cam_score))))\n",
    "#ax[0].plot(x_cs, normal_pdf_cs, c='red')\n",
    "plt.axvline(x=np.mean(cam_score), ls='--', lw=2, c='black')\n",
    "plt.axvline(x=np.mean(cam_score)+1*np.std(cam_score), ls='--', lw=1, c='black', label='Mean +/- SD')\n",
    "plt.axvline(x=np.mean(cam_score)-1*np.std(cam_score), ls='--', lw=1, c='black')\n",
    "plt.xlabel('CAM score', fontsize=16)\n",
    "plt.ylabel('count', fontsize=16)\n",
    "plt.legend(loc=2, fontsize=14)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-pontiac",
   "metadata": {},
   "source": [
    "### Correct and false predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble_binary = [0 if pred<0.5 else 1 for pred in y_pred_ensemble]\n",
    "\n",
    "correct_predictions = np.where(y_true==y_pred_ensemble_binary)\n",
    "wrong_predictions   = np.where(y_true!=y_pred_ensemble_binary)\n",
    "\n",
    "pred_result = np.empty(shape=(X_test.shape[0]), dtype=object)\n",
    "pred_result[correct_predictions] = 'correct'\n",
    "pred_result[wrong_predictions]   = 'wrong'\n",
    "\n",
    "correct_predictions, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.boxplot(x=pred_result, y=cam_score, palette=\"Set2\")\n",
    "plt.xlabel(\"prediction correct\", fontsize=16)\n",
    "plt.ylabel(\"CAM score\", fontsize=16)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-breeding",
   "metadata": {},
   "source": [
    "## Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-hybrid",
   "metadata": {},
   "source": [
    "### Figure 4 - GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info['histology'][df_info['histology']==10]='hyperlastisch'\n",
    "df_info['histology'][df_info['histology']==17]='regulär'\n",
    "df_info['histology'][df_info['histology']==11]='lipomatös'\n",
    "df_info['histology'][df_info['histology']==14]='tubulovillös'\n",
    "df_info['histology'][df_info['histology']==16]='tubulovillös'\n",
    "df_info['histology'][df_info['histology']==13]='tubulär'\n",
    "df_info['histology'][df_info['histology']==15]='villös'\n",
    "df_info['histology'][df_info['histology']==1] ='adenocarcinoma'\n",
    "df_info['histology'][df_info['histology']==12]='adenomatous'\n",
    "histo_label = df_info['histology'].values\n",
    "histo_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(histo_label=='adenocarcinoma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_fig4(X, cam, seg, cam_nr, modality, y_true, y_pred, histo_label, sample_a, sample_b, sample_c, slice_z_a, slice_z_b, slice_z_c, alpha, cmap, reverse_cmap, save):\n",
    "     \n",
    "    # Normalize image\n",
    "    X = np.copy(X)\n",
    "    X[...,0] = np.divide(X[...,0],np.amax(X[...,0]))\n",
    "    if modality>0:\n",
    "        X[...,1] = np.divide(X[...,1],np.amax(X[...,1]))\n",
    "    \n",
    "    # Colormap\n",
    "    color_map = plt.cm.get_cmap(cmap)\n",
    "    if reverse_cmap:\n",
    "        color_map = color_map.reversed()\n",
    "    \n",
    "    print('A:')\n",
    "    print('\\tImage   {:d}: [{:.2f}, {:.2f}]'.format(sample_a,np.amin(X[sample_a]),np.amax(X[sample_a])))\n",
    "    print('\\tCam     {:d}: [{:.2f}, {:.2f}]'.format(sample_a,np.amin(cam[cam_nr,sample_a]),np.amax(cam[cam_nr,sample_a])))\n",
    "    print('\\tTrue label:  {:d}'.format(y_true[sample_a]))\n",
    "    print('\\tPrediction:  {:.2f}'.format(y_pred[sample_a]))\n",
    "    print('\\tHisto label: {:s}'.format(histo_label[sample_a]))\n",
    "    \n",
    "    print('B:')\n",
    "    print('\\tImage   {:d}: [{:.2f}, {:.2f}]'.format(sample_b,np.amin(X[sample_b]),np.amax(X[sample_b])))\n",
    "    print('\\tCam     {:d}: [{:.2f}, {:.2f}]'.format(sample_b,np.amin(cam[cam_nr,sample_b]),np.amax(cam[cam_nr,sample_b])))\n",
    "    print('\\tTrue label:  {:d}'.format(y_true[sample_b]))\n",
    "    print('\\tPrediction:  {:.2f}'.format(y_pred[sample_b]))\n",
    "    print('\\tHisto label: {:s}'.format(histo_label[sample_b]))\n",
    "    \n",
    "    print('C:')\n",
    "    print('\\tImage   {:d}: [{:.2f}, {:.2f}]'.format(sample_c,np.amin(X[sample_c]),np.amax(X[sample_c])))\n",
    "    print('\\tCam     {:d}: [{:.2f}, {:.2f}]'.format(sample_c,np.amin(cam[cam_nr,sample_c]),np.amax(cam[cam_nr,sample_c])))\n",
    "    print('\\tTrue label:  {:d}'.format(y_true[sample_c]))\n",
    "    print('\\tPrediction:  {:.2f}'.format(y_pred[sample_c]))\n",
    "    print('\\tHisto label: {:s}'.format(histo_label[sample_c]))\n",
    "    \n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18,6), sharey=True)\n",
    "    \n",
    "    im = plt.imshow(np.zeros((50,50)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=1.0)\n",
    "    \n",
    "    # Original input image\n",
    "    #ax[0,0].imshow(X[sample_a,:,slice_z_a,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    #ax[0,1].imshow(X[sample_b,:,:,slice_z_b,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    #ax[0,2].imshow(X[sample_c,slice_z_c,:,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    # Original input image with GradCAM on top\n",
    "    ax[0].imshow(np.rot90(X[sample_a,:,slice_z_a,:,modality],k=3,axes=(0,1)), cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    ax[1].imshow(np.rot90(X[sample_b,:,:,slice_z_b,modality],k=3,axes=(0,1)), cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    ax[2].imshow(np.rot90(X[sample_c,slice_z_c,:,:,modality],k=3,axes=(0,1)), cmap=plt.cm.get_cmap('gist_yarg').reversed(), vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    ax[0].imshow(np.rot90(cam[cam_nr,sample_a,:,slice_z_a,:],k=3,axes=(0,1)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[1].imshow(np.rot90(cam[cam_nr,sample_b,:,:,slice_z_b],k=3,axes=(0,1)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[2].imshow(np.rot90(cam[cam_nr,sample_c,slice_z_c,:,:],k=3,axes=(0,1)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    \n",
    "    ax[0].set_xlabel('x', fontsize=16)\n",
    "    ax[0].set_ylabel('y', fontsize=16)\n",
    "    ax[1].set_xlabel('x', fontsize=16)\n",
    "    ax[2].set_xlabel('x', fontsize=16)\n",
    "    \n",
    "    # Settings\n",
    "    for axis in ax.flatten():\n",
    "        axis.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.8075, 0.158, 0.025, 0.742])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar_ax.tick_params(labelsize=14)\n",
    "    if save:\n",
    "        plt.savefig('results/cnn_paper/grad_cam_figure.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(plotter_fig4,\n",
    "            X            = fixed(X_test), #fixed(np.rot90(X_test, axes=(1, 2))),\n",
    "            cam          = fixed(cam_ensemble), #fixed(np.rot90(cam_ensemble, axes=(2, 3))),\n",
    "            seg          = fixed(X_seg), #fixed(np.rot90(X_seg, axes=(1, 2))),\n",
    "            y_true       = fixed(y_true),\n",
    "            y_pred       = fixed(y_pred_ensemble),\n",
    "            histo_label  = fixed(histo_label),\n",
    "            sample_a     = fixed(109), #(0,X_test.shape[0]-1),\n",
    "            sample_b     = fixed(73), #(0,X_test.shape[0]-1),\n",
    "            sample_c     = fixed(48), #(0,X_test.shape[0]-1),\n",
    "            cam_nr       = (0,cam_ensemble.shape[0]-1),\n",
    "            modality     = (0,X_test.shape[4]-1),\n",
    "            slice_z_a    = (0,X_test.shape[3]-1),\n",
    "            slice_z_b    = (0,X_test.shape[3]-1),\n",
    "            slice_z_c    = (0,X_test.shape[3]-1),\n",
    "            alpha        = (0.0,1.0),\n",
    "            cmap         = [\"inferno\", \"cool\", \"gist_yarg\", \"jet\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [False, True],\n",
    "            save         = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-advisory",
   "metadata": {},
   "source": [
    "A: 109 (coronal, 26), B: 73 (axial, 25), C: 48 (saggital, 26) (noch richtig ausrichten)\n",
    "\n",
    "Zwei versionen: Mit CT & ohne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.iloc[109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.iloc[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.iloc[48]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
