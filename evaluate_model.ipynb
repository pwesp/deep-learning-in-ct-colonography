{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portable-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   ipywidgets import interactive, fixed\n",
    "import matplotlib.pyplot as plt\n",
    "from   model.cnn import CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from   source.dataloader import ValidationDataGenerator\n",
    "from   source.metrics import roc_auc\n",
    "from   source.preprocessing import get_preprocessed_polyp_segmentation_mask_info\n",
    "from   source.visualization import plotter_batch\n",
    "import tensorflow as tf\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-fossil",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advance-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"preprocessed-data\"\n",
    "\n",
    "# Repeated runs\n",
    "n_estimators = 2\n",
    "\n",
    "# Data\n",
    "raw_image_size = (100,100,100)\n",
    "\n",
    "# Neural network\n",
    "patch_size = (50,50,50)\n",
    "\n",
    "# Data, second channel and gaussian blob\n",
    "n_channels = 2\n",
    "\n",
    "# Fix global seed (as good as possible)\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-namibia",
   "metadata": {},
   "source": [
    "### Meta information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902182fd-ef92-432c-9add-11075f045f45",
   "metadata": {},
   "source": [
    "Load information about the CT scans from 'ct_info.csv' and get a list of the preprocessed ct scans and segmentation masks that are available from 'preprocessed-data/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-county",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>polyp</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>histopathology</th>\n",
       "      <th>class_label</th>\n",
       "      <th>position</th>\n",
       "      <th>ct_file</th>\n",
       "      <th>segmentation_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>XXX</td>\n",
       "      <td>benign</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_001.npy</td>\n",
       "      <td>demo-data/demo_seg_001.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>XXX</td>\n",
       "      <td>benign</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_002.npy</td>\n",
       "      <td>demo-data/demo_seg_002.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XXX</td>\n",
       "      <td>premalignant</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_003.npy</td>\n",
       "      <td>demo-data/demo_seg_003.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  polyp  segmentation histopathology   class_label position  \\\n",
       "0        1      1             1            XXX        benign    prone   \n",
       "1        2      2             2            XXX        benign    prone   \n",
       "2        3      3             3            XXX  premalignant    prone   \n",
       "\n",
       "                     ct_file           segmentation_file  \n",
       "0  demo-data/demo_ct_001.npy  demo-data/demo_seg_001.npy  \n",
       "1  demo-data/demo_ct_002.npy  demo-data/demo_seg_002.npy  \n",
       "2  demo-data/demo_ct_003.npy  demo-data/demo_seg_003.npy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ct_info = pd.read_csv('ct_info.csv')\n",
    "df_ct_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stretch-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>polyp</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>preprocessed_ct_file</th>\n",
       "      <th>preprocessed_segmentation_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  polyp  segmentation  \\\n",
       "0        1      1             1   \n",
       "1        2      2             2   \n",
       "2        3      3             3   \n",
       "\n",
       "                                preprocessed_ct_file  \\\n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "1  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "\n",
       "                      preprocessed_segmentation_file  \n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "1  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed_info = get_preprocessed_polyp_segmentation_mask_info(data_dir)\n",
    "df_preprocessed_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946d88a-218a-4b42-b027-08a73b79d88d",
   "metadata": {},
   "source": [
    "Merge information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78bb52d-d605-4a4e-bc5f-e1203c92480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>polyp</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>histopathology</th>\n",
       "      <th>class_label</th>\n",
       "      <th>position</th>\n",
       "      <th>ct_file</th>\n",
       "      <th>segmentation_file</th>\n",
       "      <th>preprocessed_ct_file</th>\n",
       "      <th>preprocessed_segmentation_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>XXX</td>\n",
       "      <td>benign</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_001.npy</td>\n",
       "      <td>demo-data/demo_seg_001.npy</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>XXX</td>\n",
       "      <td>benign</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_002.npy</td>\n",
       "      <td>demo-data/demo_seg_002.npy</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XXX</td>\n",
       "      <td>premalignant</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_003.npy</td>\n",
       "      <td>demo-data/demo_seg_003.npy</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  polyp  segmentation histopathology   class_label position  \\\n",
       "0        1      1             1            XXX        benign    prone   \n",
       "1        2      2             2            XXX        benign    prone   \n",
       "2        3      3             3            XXX  premalignant    prone   \n",
       "\n",
       "                     ct_file           segmentation_file  \\\n",
       "0  demo-data/demo_ct_001.npy  demo-data/demo_seg_001.npy   \n",
       "1  demo-data/demo_ct_002.npy  demo-data/demo_seg_002.npy   \n",
       "2  demo-data/demo_ct_003.npy  demo-data/demo_seg_003.npy   \n",
       "\n",
       "                                preprocessed_ct_file  \\\n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "1  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "\n",
       "                      preprocessed_segmentation_file  \n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "1  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_ct_info.merge(df_preprocessed_info, how='inner', on=['patient', 'polyp', 'segmentation'])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9321d8-dabd-4c4f-8b53-d9edefa1cd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>polyp</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>histopathology</th>\n",
       "      <th>class_label</th>\n",
       "      <th>position</th>\n",
       "      <th>ct_file</th>\n",
       "      <th>segmentation_file</th>\n",
       "      <th>preprocessed_ct_file</th>\n",
       "      <th>preprocessed_segmentation_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>XXX</td>\n",
       "      <td>benign</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_001.npy</td>\n",
       "      <td>demo-data/demo_seg_001.npy</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>XXX</td>\n",
       "      <td>premalignant</td>\n",
       "      <td>prone</td>\n",
       "      <td>demo-data/demo_ct_003.npy</td>\n",
       "      <td>demo-data/demo_seg_003.npy</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "      <td>/home/philipp/Projects/deep-learning-ct-colono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  polyp  segmentation histopathology   class_label position  \\\n",
       "0        1      1             1            XXX        benign    prone   \n",
       "2        3      3             3            XXX  premalignant    prone   \n",
       "\n",
       "                     ct_file           segmentation_file  \\\n",
       "0  demo-data/demo_ct_001.npy  demo-data/demo_seg_001.npy   \n",
       "2  demo-data/demo_ct_003.npy  demo-data/demo_seg_003.npy   \n",
       "\n",
       "                                preprocessed_ct_file  \\\n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...   \n",
       "\n",
       "                      preprocessed_segmentation_file  \n",
       "0  /home/philipp/Projects/deep-learning-ct-colono...  \n",
       "2  /home/philipp/Projects/deep-learning-ct-colono...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.iloc[[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-sellers",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Keras datagenerator (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neutral-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ValidationDataGenerator(data=df_data,\n",
    "                                         batch_size=df_data.shape[0],\n",
    "                                         patch_size=patch_size,\n",
    "                                         n_channels=n_channels,\n",
    "                                         num_threads=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-measurement",
   "metadata": {},
   "source": [
    "#### Inspect test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectible-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_batch: (3, 50, 50, 50, 2) , y_test_batch: (3,)\n"
     ]
    }
   ],
   "source": [
    "test_batch   = data_generator[0]\n",
    "X_test_batch = test_batch[0]\n",
    "y_test_batch = test_batch[1]\n",
    "print('X_test_batch:', X_test_batch.shape, ', y_test_batch:', y_test_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fluid-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0b74b28933481fb36502aea6bec47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='sample_nr', max=2), IntSlider(value=0, description='chan…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plotter_batch,\n",
    "            batch        = fixed(test_batch),\n",
    "            sample_nr    = (0,X_test_batch.shape[0]-1),\n",
    "            channel      = (0,X_test_batch.shape[4]-1),\n",
    "            slice_x      = (0,X_test_batch.shape[1]-1),\n",
    "            slice_y      = (0,X_test_batch.shape[2]-1),\n",
    "            slice_z      = (0,X_test_batch.shape[3]-1),\n",
    "            cmap         = [\"gist_yarg\", \"cool\", \"inferno\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-subsection",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interracial-protest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 50, 50, 50,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2a (Conv3D)         (None, 25, 25, 25, 1 880         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1a_branch2a (BatchNormalizati (None, 25, 25, 25, 1 64          res1a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 25, 25, 25, 1 0           bn1a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch2b (Conv3D)         (None, 25, 25, 25, 1 6928        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res1a_branch1 (Conv3D)          (None, 25, 25, 25, 1 48          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn1a_branch2b (BatchNormalizati (None, 25, 25, 25, 1 64          res1a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn1a_branch1 (BatchNormalizatio (None, 25, 25, 25, 1 64          res1a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 25, 25, 25, 1 0           bn1a_branch2b[0][0]              \n",
      "                                                                 bn1a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 25, 25, 25, 1 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2a (Conv3D)         (None, 25, 25, 25, 1 6928        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1b_branch2a (BatchNormalizati (None, 25, 25, 25, 1 64          res1b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, 25, 25, 1 0           bn1b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res1b_branch2b (Conv3D)         (None, 25, 25, 25, 1 6928        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn1b_branch2b (BatchNormalizati (None, 25, 25, 25, 1 64          res1b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 25, 25, 1 0           bn1b_branch2b[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 25, 25, 25, 1 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv3D)         (None, 13, 13, 13, 3 13856       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 13, 13, 13, 3 128         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 13, 13, 13, 3 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv3D)         (None, 13, 13, 13, 3 27680       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv3D)          (None, 13, 13, 13, 3 544         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 13, 13, 13, 3 128         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 13, 13, 13, 3 128         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 13, 13, 13, 3 0           bn2a_branch2b[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 13, 3 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv3D)         (None, 13, 13, 13, 3 27680       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 13, 13, 13, 3 128         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 13, 13, 3 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv3D)         (None, 13, 13, 13, 3 27680       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 13, 13, 13, 3 128         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 13, 13, 13, 3 0           bn2b_branch2b[0][0]              \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 13, 3 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv3D)         (None, 7, 7, 7, 64)  55360       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 7, 7, 7, 64)  256         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 7, 64)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv3D)         (None, 7, 7, 7, 64)  110656      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv3D)          (None, 7, 7, 7, 64)  2112        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 7, 7, 7, 64)  256         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 7, 7, 7, 64)  256         res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 7, 7, 7, 64)  0           bn3a_branch2b[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 7, 64)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv3D)         (None, 7, 7, 7, 64)  110656      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 7, 7, 7, 64)  256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 7, 7, 64)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv3D)         (None, 7, 7, 7, 64)  110656      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 7, 7, 7, 64)  256         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 7, 7, 7, 64)  0           bn3b_branch2b[0][0]              \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 7, 64)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling3 (None, 64)           0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 1)            65          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 1)            0           fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 510,897\n",
      "Trainable params: 509,777\n",
      "Non-trainable params: 1,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN(input_shape=(50, 50, 50, n_channels), classes=1, dropout=0.1, mc=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-lesbian",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fallen-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator: 0\n",
      "\tLoad weights: weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_1\n",
      "\n",
      "Estimator: 1\n",
      "\tLoad weights: weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_2\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for est in range(n_estimators):\n",
    "    \n",
    "    print('\\nEstimator: {:d}'.format(est))\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    weights = 'weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_{:s}'.format(str(est+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\tLoad weights: {:s}'.format(weights))\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    # Model predictions\n",
    "    predictions_estimator = np.asarray(model.predict(data_generator))\n",
    "    predictions.append(predictions_estimator)\n",
    "    \n",
    "predictions = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9f4bf-5a38-4b23-9703-3caae40a39e4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "informal-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = np.asarray(data_generator[0][1])\n",
    "\n",
    "# Ensemble predictions\n",
    "y_pred_ensemble = np.mean(predictions.squeeze(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooperative-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC = 0.50\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC-AUC\n",
    "ensemble_roc_auc = roc_auc(y_true, y_pred_ensemble).numpy()\n",
    "print('ROC_AUC = {:.2f}'.format(ensemble_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-marketing",
   "metadata": {},
   "source": [
    "### GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "understood-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output):\n",
    "    loss_list  = [output[i][0] for i in range(df_data.shape[0])]\n",
    "    loss_tuple = tuple(loss_list)\n",
    "    return loss_tuple # (output[0][true_class[0]], output[1][true_class[1]], ...)\n",
    "\n",
    "def model_modifier(m):\n",
    "    m.layers[-1].activation = tf.keras.activations.linear\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "serial-lobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add_5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[47].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "laughing-flashing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GradCAM++ for Estimator 0\n",
      "\tLoad weights: weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_1\n",
      "\n",
      "GradCAM++ for Estimator 1\n",
      "\tLoad weights: weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_2\n"
     ]
    }
   ],
   "source": [
    "from tf_keras_vis.gradcam import GradcamPlusPlus\n",
    "from tf_keras_vis.utils import normalize\n",
    "\n",
    "cams = []\n",
    "\n",
    "for est in range(n_estimators):\n",
    "    \n",
    "    print('\\nGradCAM++ for Estimator {:d}'.format(est))\n",
    "    \n",
    "    ##############################\n",
    "    ######### CNN Model ##########\n",
    "    ##############################\n",
    "    \n",
    "    # Load trained weights from disk\n",
    "    weights = 'weights/ResNet18_3D_Dropout_SecondChannel_Segmentation_Ensemble_{:s}'.format(str(est+1))\n",
    "    \n",
    "    # Load trained weights into model\n",
    "    print('\\tLoad weights: {:s}'.format(weights))\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    ############################\n",
    "    ######### GradCAM ##########\n",
    "    ############################\n",
    "    \n",
    "    # Create Gradcam object\n",
    "    gradcam = GradcamPlusPlus(model,\n",
    "                              model_modifier=model_modifier,\n",
    "                              clone=False)\n",
    "\n",
    "    # Generate heatmap with GradCAM form first neuron\n",
    "    cam_est = gradcam(loss,\n",
    "                      X_test_batch,\n",
    "                      penultimate_layer=47, # model.layers number\n",
    "                      seek_penultimate_conv_layer=False)\n",
    "    cam_est = normalize(cam_est)\n",
    "    \n",
    "    # Store GradCAM\n",
    "    cams.append(cam_est)\n",
    "    \n",
    "cams = np.asarray(cams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-theorem",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "choice-simulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_data_generator = ValidationDataGenerator(data=df_data,\n",
    "                                             batch_size=df_data.shape[0],\n",
    "                                             patch_size=patch_size,\n",
    "                                             n_channels=n_channels,\n",
    "                                             num_threads=1,\n",
    "                                             shuffle=False)\n",
    "\n",
    "\n",
    "X_seg = seg_data_generator[0][0][...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surgical-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "def plotter_gradcam(X, cam, seg, cam_nr, modality, y_true, y_pred, sample_nr, slice_x, slice_y, slice_z, alpha, threshold, cmap, reverse_cmap):\n",
    "     \n",
    "    # Pick and normalize image\n",
    "    X = np.copy(X[sample_nr])\n",
    "    X[...,0] = np.divide(X[...,0],np.amax(X[...,0]))\n",
    "    if modality>0:\n",
    "        X[...,1] = np.divide(X[...,1],np.amax(X[...,1]))\n",
    "    \n",
    "    # Pick cam\n",
    "    cam = np.copy(cam[cam_nr,sample_nr,...])\n",
    "    \n",
    "    # Pick segmentation\n",
    "    seg = np.copy(seg[sample_nr])\n",
    "    \n",
    "    # Colormap\n",
    "    color_map = plt.cm.get_cmap(cmap)\n",
    "    if reverse_cmap:\n",
    "        color_map = color_map.reversed()\n",
    "        \n",
    "    print('Image {:d}: [{:.2f}, {:.2f}]'.format(sample_nr,np.amin(X),np.amax(X)))\n",
    "    print('Cam   {:d}: [{:.2f}, {:.2f}]'.format(sample_nr,np.amin(cam),np.amax(cam)))\n",
    "    print('True label: {:d}'.format(y_true[sample_nr]))\n",
    "    print('Prediction: {:.2f}'.format(y_pred[sample_nr]))\n",
    "    \n",
    "    # Threshold\n",
    "    X_in = np.zeros_like(X[...,modality])\n",
    "    X_in[np.where(cam>=threshold)]=1\n",
    "    X_out = np.zeros_like(X[...,modality])\n",
    "    \n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(14,7.6), sharex=True, sharey=True)\n",
    "    \n",
    "    # Original input image with GradCAM on top\n",
    "    ax[0,0].imshow(X[slice_x,:,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[0,1].imshow(X[:,slice_y,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[0,2].imshow(X[:,:,slice_z,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "\n",
    "    ax[0,0].imshow(cam[slice_x,:,:], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[0,1].imshow(cam[:,slice_y,:], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    ax[0,2].imshow(cam[:,:,slice_z], cmap=color_map, vmin=0.0, vmax=1.0, alpha=alpha) # overlay\n",
    "    \n",
    "    ax[0,0].set_xlabel('y', fontsize=16)\n",
    "    ax[0,0].set_ylabel('z', fontsize=16)\n",
    "    ax[0,1].set_xlabel('x', fontsize=16)\n",
    "    ax[0,1].set_ylabel('z', fontsize=16)\n",
    "    ax[0,2].set_xlabel('x', fontsize=16)\n",
    "    ax[0,2].set_ylabel('y', fontsize=16)\n",
    "    \n",
    "    im = plt.imshow(np.zeros((50,50)), cmap=color_map, vmin=0.0, vmax=1.0, alpha=1.0)\n",
    "    \n",
    "    # Binarized CT\n",
    "    ax[1,0].imshow(X[slice_x,:,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[1,1].imshow(X[:,slice_y,:,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    ax[1,2].imshow(X[:,:,slice_z,modality], cmap=plt.cm.get_cmap('gist_yarg').reversed())\n",
    "    \n",
    "    ax[1,0].imshow(X_in[slice_x,:,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,1].imshow(X_in[:,slice_y,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,2].imshow(X_in[:,:,slice_z], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    \n",
    "    ax[1,0].imshow(X_out[slice_x,:,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,1].imshow(X_out[:,slice_y,:], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    ax[1,2].imshow(X_out[:,:,slice_z], cmap=plt.cm.get_cmap('bwr'), alpha=0.6)\n",
    "    \n",
    "    ax[1,0].set_xlabel('y', fontsize=16)\n",
    "    ax[1,0].set_ylabel('z', fontsize=16)\n",
    "    ax[1,1].set_xlabel('x', fontsize=16)\n",
    "    ax[1,1].set_ylabel('z', fontsize=16)\n",
    "    ax[1,2].set_xlabel('x', fontsize=16)\n",
    "    ax[1,2].set_ylabel('y', fontsize=16)\n",
    "    \n",
    "    # Settings\n",
    "    for axis in ax.flatten():\n",
    "        axis.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.8, 0.09, 0.025, 0.885])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar_ax.tick_params(labelsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brilliant-vitamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45518b822b6a4f44a553ff06e25df5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='cam_nr', max=1), IntSlider(value=0, description='modalit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plotter_gradcam,\n",
    "            X            = fixed(X_test_batch),\n",
    "            cam          = fixed(cams),\n",
    "            seg          = fixed(X_seg),\n",
    "            y_true       = fixed(y_true),\n",
    "            y_pred       = fixed(y_pred_ensemble),\n",
    "            sample_nr    = (0,X_test_batch.shape[0]-1),\n",
    "            cam_nr       = (0,cams.shape[0]-1),\n",
    "            modality     = (0,X_test_batch.shape[4]-1),\n",
    "            slice_x      = (0,X_test_batch.shape[1]-1),\n",
    "            slice_y      = (0,X_test_batch.shape[2]-1),\n",
    "            slice_z      = (0,X_test_batch.shape[3]-1),\n",
    "            alpha        = (0.0,1.0),\n",
    "            threshold    = (0.0,1.0,0.05),\n",
    "            cmap         = [\"inferno\", \"cool\", \"gist_yarg\", \"jet\", \"magma\", \"plasma\", \"viridis\"],\n",
    "            reverse_cmap = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-ordinary",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GradCAM++ activation in segmented voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dutch-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcfd5c59-ecde-4e8c-b545-6e93495c6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_voxels_seg = X_seg[X_seg==1.0].shape[0]\n",
    "\n",
    "aggregated_cam             = np.mean(cams, axis=0)\n",
    "aggregated_cam[X_seg==0.0] = 0.0\n",
    "n_voxels_high_act          = aggregated_cam[aggregated_cam>=activation_threshold].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc8da483-bae0-407a-9420-83cd8ce5791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of segmented voxels with a GradCAM++ activation > 0.25: 100.00% (771/771)\n"
     ]
    }
   ],
   "source": [
    "p_high_act = float(n_voxels_high_act) / float(n_voxels_seg)\n",
    "print('Fraction of segmented voxels with a GradCAM++ activation > {:.2f}: {:.2f}% ({:d}/{:d})'.format(activation_threshold, 100*p_high_act, n_voxels_high_act, n_voxels_seg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
